{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d78ad6e7",
   "metadata": {},
   "source": [
    "# SQL 데이터베이스와 상호작용하는 에이전트\n",
    "\n",
    "이 튜토리얼에서는 **SQL 데이터베이스에 대한 질문에 답할 수 있는 에이전트**를 단계별로 구축하는 방법을 소개합니다.  \n",
    "\n",
    "SQL 쿼리를 실행하는 에이전트의 흐름은 다음과 같습니다.\n",
    "\n",
    "1. **데이터베이스 스키마 파악**: 사용 가능한 테이블 목록을 가져옵니다.\n",
    "2. **관련 테이블 선택**: 질문과 연관된 테이블을 선택합니다.\n",
    "3. **DDL 조회**: 선택된 테이블의 스키마 정의(DDL)를 가져옵니다.\n",
    "4. **쿼리 생성**: 질문과 DDL 정보에 기반하여 SQL 쿼리를 작성합니다.\n",
    "5. **쿼리 점검**: LLM을 사용하여 일반적인 오류를 검토하고 쿼리를 개선합니다.\n",
    "6. **쿼리 실행 및 오류 처리**: 데이터베이스 엔진에 쿼리를 실행하고, 오류 발생 시 수정하여 성공적으로 쿼리를 수행합니다.\n",
    "7. **응답 생성**: 쿼리 결과를 기반으로 최종 답변을 제공합니다.\n",
    "\n",
    "![](./assets/langgraph-sql-agent.png)\n",
    "\n",
    "---\n",
    "\n",
    "**주요 내용**\n",
    "\n",
    "- **데이터베이스**: SQLite 데이터베이스 설정 및 `chinook` 샘플 데이터베이스 로드  \n",
    "- **유틸리티 함수**: 에이전트 구현을 위한 유틸리티 함수 정의  \n",
    "- **도구 정의**: 데이터베이스와 상호작용하기 위한 도구 정의  \n",
    "- **워크플로우 정의**: 에이전트의 워크플로우(그래프) 정의  \n",
    "- **그래프 시각화**: 정의된 그래프 시각화  \n",
    "- **에이전트 실행**: 에이전트 실행 및 결과 확인  \n",
    "- **평가**: 에이전트 평가 및 성능 비교  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8000125",
   "metadata": {},
   "source": [
    "## 환경 설정\n",
    "\n",
    "먼저, 필요한 패키지를 설치하고 API 키를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af24e6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b57903b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH17-LangGraph-Use-Cases\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH17-LangGraph-Use-Cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3743ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용하는 모델명: gpt-4o\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.models import get_model_name, LLMs\n",
    "\n",
    "MODEL_NAME = get_model_name(LLMs.GPT4o)\n",
    "print(f\"사용하는 모델명: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22810c3",
   "metadata": {},
   "source": [
    "## 데이터베이스 설정\n",
    "\n",
    "이 튜토리얼에서는 SQLite 데이터베이스를 생성합니다. SQLite는 설정과 사용이 간편한 경량 데이터베이스입니다. \n",
    "\n",
    "이번 튜토리얼에서는 샘플 데이터베이스인 `chinook` 데이터베이스를 로드할 예정이며, 이는 디지털 미디어 스토어를 나타내는 샘플 데이터베이스입니다. \n",
    "\n",
    "데이터베이스에 대한 자세한 정보는 [여기](https://www.sqlitetutorial.net/sqlite-sample-database/)에서 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea4a58",
   "metadata": {},
   "source": [
    "먼저, 실습에 활용할 `chinook` 데이터베이스를 다운로드 받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fc78225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as Chinook.db\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://storage.googleapis.com/benchmarks-artifacts/chinook/Chinook.db\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(\"Chinook.db\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    print(\"File downloaded and saved as Chinook.db\")\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013e66ea",
   "metadata": {},
   "source": [
    "다음은 다운로드 받은 `chinook` 데이터베이스를 사용하여 `SQLDatabase` 도구를 생성하고 샘플 쿼리인 `\"SELECT * FROM Artist LIMIT 5;\"`를 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "766ea943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains')]\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "# SQLite 데이터베이스 파일에서 SQLDatabase 인스턴스 생성\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
    "\n",
    "# DB dialect 출력(sqlite)\n",
    "print(db.dialect)\n",
    "\n",
    "# 데이터베이스에서 사용 가능한 테이블 이름 목록 출력\n",
    "print(db.get_usable_table_names())\n",
    "\n",
    "# SQL 쿼리 실행\n",
    "db.run(\"SELECT * FROM Artist LIMIT 5;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1ea840",
   "metadata": {},
   "source": [
    "## 유틸리티 함수\n",
    "\n",
    "에이전트 구현을 돕기 위해 몇 가지 유틸리티 함수를 정의합니다. \n",
    "\n",
    "특히, `ToolNode`를 **오류 처리** 와 **에이전트에 오류를 전달하는 기능** 을 포함하여 래핑합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ba2ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.runnables import RunnableLambda, RunnableWithFallbacks\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "# 오류 처리 함수\n",
    "def handle_tool_error(state) -> dict:\n",
    "    # 오류 정보 조회\n",
    "    error = state.get(\"error\")\n",
    "    # 도구 정보 조회\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    # ToolMessage 로 래핑 후 반환\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Here is the error: {repr(error)}\\n\\nPlease fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            )\n",
    "            for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "# 오류를 처리하고 에이전트에 오류를 전달하기 위한 ToolNode 생성\n",
    "def create_tool_node_with_fallback(tools: list) -> RunnableWithFallbacks[Any, dict]:\n",
    "    \"\"\"\n",
    "    Create a ToolNode with a fallback to handle errors and surface them to the agent.\n",
    "    \"\"\"\n",
    "    # 오류 발생 시 대체 동작을 정의하여 ToolNode에 추가\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be7a514",
   "metadata": {},
   "source": [
    "## SQL 쿼리 실행 도구 \n",
    "\n",
    "에이전트가 데이터베이스와 상호작용할 수 있도록 몇 가지 도구를 정의합니다.\n",
    "\n",
    "1. `list_tables_tool`: 데이터베이스에서 사용 가능한 테이블을 가져옵니다.\n",
    "2. `get_schema_tool`: 테이블의 DDL을 가져옵니다.\n",
    "3. `db_query_tool`: 쿼리를 실행하고 결과를 가져오거나 쿼리가 실패할 경우 오류 메시지를 반환합니다.\n",
    "\n",
    "**참고**\n",
    "\n",
    "- DDL(데이터 정의 언어, **Data Definition Language**)은 데이터베이스의 구조와 스키마를 정의하거나 수정하는 데 사용되는 SQL 명령어들을 지칭합니다. 주로 테이블, 인덱스, 뷰, 스키마 등의 데이터베이스 객체를 생성, 수정, 삭제할 때 사용됩니다.\n",
    "\n",
    "주요 DDL 명령어\n",
    "\n",
    "- **`CREATE`**: 데이터베이스 객체를 생성합니다.\n",
    "  - 예: `CREATE TABLE users (id INT, name VARCHAR(100));`\n",
    "- **`ALTER`**: 기존 데이터베이스 객체를 수정합니다.\n",
    "  - 예: `ALTER TABLE users ADD COLUMN email VARCHAR(100);`\n",
    "- **`DROP`**: 데이터베이스 객체를 삭제합니다.\n",
    "  - 예: `DROP TABLE users;`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be594e8c",
   "metadata": {},
   "source": [
    "### 데이터베이스 쿼리 관련 도구\n",
    "\n",
    "다음은 SQL database와 상호작용하기 위한 `SQLDatabaseToolkit` 도구 목록입니다.\n",
    "\n",
    "**QuerySQLDataBaseTool**\n",
    "\n",
    "- **기능**: SQL query 실행 및 결과 반환\n",
    "- **Input**: 정확한 SQL query\n",
    "- **Output**: Database 결과 또는 error message\n",
    "- **Error 처리**:\n",
    "  - Query 오류 발생 시 재작성 및 재시도\n",
    "  - `Unknown column` 오류 시 `sql_db_schema`로 정확한 table fields 확인\n",
    "\n",
    "**InfoSQLDatabaseTool**\n",
    "\n",
    "- **기능**: Table schema 및 sample data 조회\n",
    "- **Input**: 콤마로 구분된 table 목록\n",
    "- **사용 예시**: `table1, table2, table3`\n",
    "- **주의사항**: `sql_db_list_tables`로 table 존재 여부 사전 확인 필요\n",
    "\n",
    "**ListSQLDatabaseTool**\n",
    "\n",
    "- **기능**: Database 내 table 목록 조회\n",
    "\n",
    "**QuerySQLCheckerTool**\n",
    "\n",
    "- **기능**: Query 실행 전 유효성 검사\n",
    "- **검사 항목**:\n",
    "  - NULL 값과 NOT IN 사용\n",
    "  - UNION vs UNION ALL 적절성\n",
    "  - BETWEEN 범위 설정\n",
    "  - Data type 일치 여부\n",
    "  - Identifier 인용 적절성\n",
    "  - Function argument 수\n",
    "  - Data type casting\n",
    "  - Join column 정확성\n",
    "- **특징**: GPT-4 model 기반 검증 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d301860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[QuerySQLDatabaseTool(description=\"Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\", db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x000001CAD297C710>),\n",
       " InfoSQLDatabaseTool(description='Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x000001CAD297C710>),\n",
       " ListSQLDatabaseTool(db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x000001CAD297C710>),\n",
       " QuerySQLCheckerTool(description='Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x000001CAD297C710>, llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001CAD3037390>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001CAD2BD0AD0>, root_client=<openai.OpenAI object at 0x000001CAD2AD9950>, root_async_client=<openai.AsyncOpenAI object at 0x000001CAD30FD0D0>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********')), llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['dialect', 'query'], input_types={}, partial_variables={}, template='\\n{query}\\nDouble check the {dialect} query above for common mistakes, including:\\n- Using NOT IN with NULL values\\n- Using UNION when UNION ALL should have been used\\n- Using BETWEEN for exclusive ranges\\n- Data type mismatch in predicates\\n- Properly quoting identifiers\\n- Using the correct number of arguments for functions\\n- Casting to the correct data type\\n- Using the proper columns for joins\\n\\nIf there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\\n\\nOutput the final SQL query only.\\n\\nSQL Query: '), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001CAD3037390>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001CAD2BD0AD0>, root_client=<openai.OpenAI object at 0x000001CAD2AD9950>, root_async_client=<openai.AsyncOpenAI object at 0x000001CAD30FD0D0>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# SQLDatabaseToolkit 생성\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=ChatOpenAI(model=MODEL_NAME))\n",
    "\n",
    "# SQLDatabaseToolkit에서 사용 가능한 도구 목록\n",
    "tools = toolkit.get_tools()\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28a0eeb",
   "metadata": {},
   "source": [
    "아래는 `list_tables_tool` 과 `get_schema_tool` 에 대한 실행 예시입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19bb31d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\n",
      "\n",
      "CREATE TABLE \"Artist\" (\n",
      "\t\"ArtistId\" INTEGER NOT NULL, \n",
      "\t\"Name\" NVARCHAR(120), \n",
      "\tPRIMARY KEY (\"ArtistId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Artist table:\n",
      "ArtistId\tName\n",
      "1\tAC/DC\n",
      "2\tAccept\n",
      "3\tAerosmith\n",
      "*/\n"
     ]
    }
   ],
   "source": [
    "# 데이터베이스에서 사용 가능한 테이블을 나열하는 도구 선택\n",
    "list_tables_tool = next(tool for tool in tools if tool.name == \"sql_db_list_tables\")\n",
    "\n",
    "# 특정 테이블의 DDL을 가져오는 도구 선택\n",
    "get_schema_tool = next(tool for tool in tools if tool.name == \"sql_db_schema\")\n",
    "\n",
    "# 데이터베이스의 모든 테이블 목록 출력\n",
    "print(list_tables_tool.invoke(\"\"))\n",
    "\n",
    "# Artist 테이블의 DDL 정보 출력\n",
    "print(get_schema_tool.invoke(\"Artist\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f7d7e2",
   "metadata": {},
   "source": [
    "다음은 `db_query_tool` 을 정의합니다. \n",
    "\n",
    "`db_query_tool`의 경우, 데이터베이스에 대해 쿼리를 실행하고 결과를 반환합니다.\n",
    "\n",
    "만약, error 가 발생하면 오류 메시지를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cacbfa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "# Query 실행 도구\n",
    "@tool\n",
    "def db_query_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Run SQL queries against a database and return results\n",
    "    Returns an error message if the query is incorrect\n",
    "    If an error is returned, rewrite the query, check, and retry\n",
    "    \"\"\"\n",
    "    # 쿼리 실행\n",
    "    result = db.run_no_throw(query)\n",
    "\n",
    "    # 오류: 결과가 없으면 오류 메시지 반환\n",
    "    if not result:\n",
    "        return \"Error: Query failed. Please rewrite your query and try again.\"\n",
    "    # 정상: 쿼리 실행 결과 반환\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c1cab",
   "metadata": {},
   "source": [
    "정상 실행된 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7e6af4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'Antônio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\n"
     ]
    }
   ],
   "source": [
    "# Artist 테이블에서 상위 10개 행 선택 및 실행 결과 출력\n",
    "print(db_query_tool.invoke(\"SELECT * FROM Artist LIMIT 10;\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cd6fd1",
   "metadata": {},
   "source": [
    "오류가 발생한 경우 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4769c8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: (sqlite3.OperationalError) near \"10\": syntax error\n",
      "[SQL: SELECT * FROM Artist LIMITS 10;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    }
   ],
   "source": [
    "# Artist 테이블에서 상위 10개 행 선택 및 실행 결과 출력\n",
    "print(db_query_tool.invoke(\"SELECT * FROM Artist LIMITS 10;\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdd597b",
   "metadata": {},
   "source": [
    "### SQL 쿼리 점검(SQL Query Checker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46308526",
   "metadata": {},
   "source": [
    "다음은, SQL 쿼리에서 일반적인 실수를 점검하기 위해 LLM을 활용할 예정입니다. \n",
    "\n",
    "이는 엄밀히 말하면 도구는 아니지만, 이후 워크플로우에 노드로 추가될 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f608b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# SQL 쿼리의 일반적인 실수를 점검하기 위한 시스템 메시지 정의\n",
    "query_check_system = \"\"\"You are a SQL expert with a strong attention to detail.\n",
    "Double check the SQLite query for common mistakes, including:\n",
    "- Using NOT IN with NULL values\n",
    "- Using UNION when UNION ALL should have been used\n",
    "- Using BETWEEN for exclusive ranges\n",
    "- Data type mismatch in predicates\n",
    "- Properly quoting identifiers\n",
    "- Using the correct number of arguments for functions\n",
    "- Casting to the correct data type\n",
    "- Using the proper columns for joins\n",
    "\n",
    "If there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\n",
    "\n",
    "You will call the appropriate tool to execute the query after running this check.\"\"\"\n",
    "\n",
    "# 프롬프트 생성\n",
    "query_check_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", query_check_system), (\"placeholder\", \"{messages}\")]\n",
    ")\n",
    "\n",
    "# Query Checker 체인 생성\n",
    "query_check = query_check_prompt | ChatOpenAI(\n",
    "    model=MODEL_NAME, temperature=0\n",
    ").bind_tools([db_query_tool], tool_choice=\"db_query_tool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd06a6a",
   "metadata": {},
   "source": [
    "잘못된 쿼리를 날려 호출하여 결과가 잘 수정되었는지 확인합니다.\n",
    "\n",
    "**참고**\n",
    "\n",
    "- `LIMIT` 대신 `LIMITS` 을 사용하여 쿼리를 날렸습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2355b32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_iE87199Bt0Hhywpjn6s7hDlJ', 'type': 'tool_call'}\n"
     ]
    }
   ],
   "source": [
    "# 사용자 메시지를 사용하여 쿼리 점검 노드 실행\n",
    "response = query_check.invoke(\n",
    "    {\"messages\": [(\"user\", \"SELECT * FROM Artist LIMITS 10;\")]}\n",
    ")\n",
    "print(response.tool_calls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c8ce9",
   "metadata": {},
   "source": [
    "결과는 잘 수정되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db713316",
   "metadata": {},
   "source": [
    "## 그래프 정의\n",
    "\n",
    "에이전트의 워크플로우를 정의합니다. \n",
    "\n",
    "에이전트는 먼저 `list_tables_tool`을 강제로 호출하여 데이터베이스에서 사용 가능한 테이블을 가져온 후, 튜토리얼 초반에 언급된 단계를 따릅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32474a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "\n",
    "# 에이전트의 상태 정의\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "# 새로운 그래프 정의\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "\n",
    "# 첫 번째 도구 호출을 위한 노드 추가\n",
    "def first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            AIMessage(\n",
    "                content=\"\",\n",
    "                tool_calls=[\n",
    "                    {\n",
    "                        \"name\": \"sql_db_list_tables\",\n",
    "                        \"args\": {},\n",
    "                        \"id\": \"initial_tool_call_abc123\",\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "# 쿼리의 정확성을 모델로 점검하기 위한 함수 정의\n",
    "def model_check_query(state: State) -> dict[str, list[AIMessage]]:\n",
    "    \"\"\"\n",
    "    Use this tool to check that your query is correct before you run it\n",
    "    \"\"\"\n",
    "    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n",
    "\n",
    "\n",
    "# 첫 번째 도구 호출 노드 추가\n",
    "workflow.add_node(\"first_tool_call\", first_tool_call)\n",
    "\n",
    "# 첫 번째 두 도구를 위한 노드 추가\n",
    "workflow.add_node(\n",
    "    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n",
    ")\n",
    "workflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n",
    "\n",
    "# 질문과 사용 가능한 테이블을 기반으로 관련 테이블을 선택하는 모델 노드 추가\n",
    "model_get_schema = ChatOpenAI(model=MODEL_NAME, temperature=0).bind_tools(\n",
    "    [get_schema_tool]\n",
    ")\n",
    "workflow.add_node(\n",
    "    \"model_get_schema\",\n",
    "    lambda state: {\n",
    "        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "# 최종 상태를 나타내는 도구 설명\n",
    "class SubmitFinalAnswer(BaseModel):\n",
    "    \"\"\"쿼리 결과를 기반으로 사용자에게 최종 답변 제출\"\"\"\n",
    "\n",
    "    final_answer: str = Field(..., description=\"The final answer to the user\")\n",
    "\n",
    "\n",
    "# 질문과 스키마를 기반으로 쿼리를 생성하기 위한 모델 노드 추가\n",
    "QUERY_GEN_INSTRUCTION = \"\"\"You are a SQL expert with a strong attention to detail.\n",
    "\n",
    "You can define SQL queries, analyze queries results and interpretate query results to response an answer.\n",
    "\n",
    "Read the messages bellow and identify the user question, table schemas, query statement and query result, or error if they exist.\n",
    "\n",
    "1. If there's not any query result that make sense to answer the question, create a syntactically correct SQLite query to answer the user question. DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
    "\n",
    "2. If you create a query, response ONLY the query statement. For example, \"SELECT id, name FROM pets;\"\n",
    "\n",
    "3. If a query was already executed, but there was an error. Response with the same error message you found. For example: \"Error: Pets table doesn't exist\"\n",
    "\n",
    "4. If a query was already executed successfully interpretate the response and answer the question following this pattern: Answer: <<question answer>>. For example: \"Answer: There three cats registered as adopted\"\n",
    "\"\"\"\n",
    "\n",
    "query_gen_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", QUERY_GEN_INSTRUCTION), (\"placeholder\", \"{messages}\")]\n",
    ")\n",
    "query_gen = query_gen_prompt | ChatOpenAI(model=MODEL_NAME, temperature=0).bind_tools(\n",
    "    [SubmitFinalAnswer, model_check_query]\n",
    ")\n",
    "\n",
    "\n",
    "# 조건부 에지 정의\n",
    "def should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    last_message = messages[-1]\n",
    "    if last_message.content.startswith(\"Answer:\"):\n",
    "        return END\n",
    "    if last_message.content.startswith(\"Error:\"):\n",
    "        return \"query_gen\"\n",
    "    else:\n",
    "        return \"correct_query\"\n",
    "\n",
    "\n",
    "# 쿼리 생성 노드 정의\n",
    "def query_gen_node(state: State):\n",
    "    message = query_gen.invoke(state)\n",
    "\n",
    "    # LLM이 잘못된 도구를 호출할 경우 오류 메시지를 반환\n",
    "    tool_messages = []\n",
    "    message.pretty_print()\n",
    "    if message.tool_calls:\n",
    "        for tc in message.tool_calls:\n",
    "            if tc[\"name\"] != \"SubmitFinalAnswer\":\n",
    "                tool_messages.append(\n",
    "                    ToolMessage(\n",
    "                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n",
    "                        tool_call_id=tc[\"id\"],\n",
    "                    )\n",
    "                )\n",
    "    else:\n",
    "        tool_messages = []\n",
    "    return {\"messages\": [message] + tool_messages}\n",
    "\n",
    "\n",
    "# 쿼리 생성 노드 추가\n",
    "workflow.add_node(\"query_gen\", query_gen_node)\n",
    "\n",
    "# 쿼리를 실행하기 전에 모델로 점검하는 노드 추가\n",
    "workflow.add_node(\"correct_query\", model_check_query)\n",
    "\n",
    "# 쿼리를 실행하기 위한 노드 추가\n",
    "workflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n",
    "\n",
    "# 노드 간의 엣지 지정\n",
    "workflow.add_edge(START, \"first_tool_call\")\n",
    "workflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\n",
    "workflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\n",
    "workflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\n",
    "workflow.add_edge(\"get_schema_tool\", \"query_gen\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"query_gen\",\n",
    "    should_continue,\n",
    ")\n",
    "workflow.add_edge(\"correct_query\", \"execute_query\")\n",
    "workflow.add_edge(\"execute_query\", \"query_gen\")\n",
    "\n",
    "# 실행 가능한 워크플로우로 컴파일\n",
    "app = workflow.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7d7f2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(app, xray=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e48ae3",
   "metadata": {},
   "source": [
    "## 그래프 실행\n",
    "\n",
    "에이전트를 실행하여 SQL 데이터베이스와 상호작용하는 전체 프로세스를 진행합니다.\n",
    "\n",
    "에이전트는 사용자의 질문에 따라 데이터베이스에서 정보를 검색하고, 쿼리를 생성 및 실행하여 결과를 반환합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ca79a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import random_uuid, invoke_graph, stream_graph\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.errors import GraphRecursionError\n",
    "\n",
    "\n",
    "def run_graph(\n",
    "    message: str, recursive_limit: int = 30, node_names=[], stream: bool = False\n",
    "):\n",
    "    # config 설정(재귀 최대 횟수, thread_id)\n",
    "    config = RunnableConfig(\n",
    "        recursion_limit=recursive_limit, configurable={\"thread_id\": random_uuid()}\n",
    "    )\n",
    "\n",
    "    # 질문 입력\n",
    "    inputs = {\n",
    "        \"messages\": [HumanMessage(content=message)],\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        if stream:\n",
    "            # 그래프 실행\n",
    "            stream_graph(app, inputs, config, node_names=node_names)\n",
    "        else:\n",
    "            invoke_graph(app, inputs, config, node_names=node_names)\n",
    "        output = app.get_state(config).values\n",
    "        return output\n",
    "    except GraphRecursionError as recursion_error:\n",
    "        print(f\"GraphRecursionError: {recursion_error}\")\n",
    "        output = app.get_state(config).values\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b51d2282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mfirst_tool_call\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_list_tables (initial_tool_call_abc123)\n",
      " Call ID: initial_tool_call_abc123\n",
      "  Args:\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mlist_tables_tool\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_list_tables\n",
      "\n",
      "Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mmodel_get_schema\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_schema (call_enhcaPsqukDCfhpIVUWzJyOk)\n",
      " Call ID: call_enhcaPsqukDCfhpIVUWzJyOk\n",
      "  Args:\n",
      "    table_names: Employee\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mget_schema_tool\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_schema\n",
      "\n",
      "\n",
      "CREATE TABLE \"Employee\" (\n",
      "\t\"EmployeeId\" INTEGER NOT NULL, \n",
      "\t\"LastName\" NVARCHAR(20) NOT NULL, \n",
      "\t\"FirstName\" NVARCHAR(20) NOT NULL, \n",
      "\t\"Title\" NVARCHAR(30), \n",
      "\t\"ReportsTo\" INTEGER, \n",
      "\t\"BirthDate\" DATETIME, \n",
      "\t\"HireDate\" DATETIME, \n",
      "\t\"Address\" NVARCHAR(70), \n",
      "\t\"City\" NVARCHAR(40), \n",
      "\t\"State\" NVARCHAR(40), \n",
      "\t\"Country\" NVARCHAR(40), \n",
      "\t\"PostalCode\" NVARCHAR(10), \n",
      "\t\"Phone\" NVARCHAR(24), \n",
      "\t\"Fax\" NVARCHAR(24), \n",
      "\t\"Email\" NVARCHAR(60), \n",
      "\tPRIMARY KEY (\"EmployeeId\"), \n",
      "\tFOREIGN KEY(\"ReportsTo\") REFERENCES \"Employee\" (\"EmployeeId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Employee table:\n",
      "EmployeeId\tLastName\tFirstName\tTitle\tReportsTo\tBirthDate\tHireDate\tAddress\tCity\tState\tCountry\tPostalCode\tPhone\tFax\tEmail\n",
      "1\tAdams\tAndrew\tGeneral Manager\tNone\t1962-02-18 00:00:00\t2002-08-14 00:00:00\t11120 Jasper Ave NW\tEdmonton\tAB\tCanada\tT5K 2N1\t+1 (780) 428-9482\t+1 (780) 428-3457\tandrew@chinookcorp.com\n",
      "2\tEdwards\tNancy\tSales Manager\t1\t1958-12-08 00:00:00\t2002-05-01 00:00:00\t825 8 Ave SW\tCalgary\tAB\tCanada\tT2P 2T3\t+1 (403) 262-3443\t+1 (403) 262-3322\tnancy@chinookcorp.com\n",
      "3\tPeacock\tJane\tSales Support Agent\t2\t1973-08-29 00:00:00\t2002-04-01 00:00:00\t1111 6 Ave SW\tCalgary\tAB\tCanada\tT2P 5M5\t+1 (403) 262-3443\t+1 (403) 262-6712\tjane@chinookcorp.com\n",
      "*/\n",
      "==================================================\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Answer: Andrew Adams 직원의 인적정보는 다음과 같습니다:\n",
      "- 성: Adams\n",
      "- 이름: Andrew\n",
      "- 직책: General Manager\n",
      "- 생년월일: 1962-02-18\n",
      "- 고용일: 2002-08-14\n",
      "- 주소: 11120 Jasper Ave NW, Edmonton, AB, Canada, T5K 2N1\n",
      "- 전화번호: +1 (780) 428-9482\n",
      "- 팩스: +1 (780) 428-3457\n",
      "- 이메일: andrew@chinookcorp.com\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mquery_gen\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Answer: Andrew Adams 직원의 인적정보는 다음과 같습니다:\n",
      "- 성: Adams\n",
      "- 이름: Andrew\n",
      "- 직책: General Manager\n",
      "- 생년월일: 1962-02-18\n",
      "- 고용일: 2002-08-14\n",
      "- 주소: 11120 Jasper Ave NW, Edmonton, AB, Canada, T5K 2N1\n",
      "- 전화번호: +1 (780) 428-9482\n",
      "- 팩스: +1 (780) 428-3457\n",
      "- 이메일: andrew@chinookcorp.com\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "output = run_graph(\n",
    "    \"Andrew Adam 직원의 인적정보를 모두 조회해줘\",\n",
    "    stream=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf2d13fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mfirst_tool_call\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_list_tables (initial_tool_call_abc123)\n",
      " Call ID: initial_tool_call_abc123\n",
      "  Args:\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mlist_tables_tool\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_list_tables\n",
      "\n",
      "Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mmodel_get_schema\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_schema (call_9PXeKSd8zg5fIVLrCgJd5IPh)\n",
      " Call ID: call_9PXeKSd8zg5fIVLrCgJd5IPh\n",
      "  Args:\n",
      "    table_names: Customer, Invoice\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mget_schema_tool\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_schema\n",
      "\n",
      "\n",
      "CREATE TABLE \"Customer\" (\n",
      "\t\"CustomerId\" INTEGER NOT NULL, \n",
      "\t\"FirstName\" NVARCHAR(40) NOT NULL, \n",
      "\t\"LastName\" NVARCHAR(20) NOT NULL, \n",
      "\t\"Company\" NVARCHAR(80), \n",
      "\t\"Address\" NVARCHAR(70), \n",
      "\t\"City\" NVARCHAR(40), \n",
      "\t\"State\" NVARCHAR(40), \n",
      "\t\"Country\" NVARCHAR(40), \n",
      "\t\"PostalCode\" NVARCHAR(10), \n",
      "\t\"Phone\" NVARCHAR(24), \n",
      "\t\"Fax\" NVARCHAR(24), \n",
      "\t\"Email\" NVARCHAR(60) NOT NULL, \n",
      "\t\"SupportRepId\" INTEGER, \n",
      "\tPRIMARY KEY (\"CustomerId\"), \n",
      "\tFOREIGN KEY(\"SupportRepId\") REFERENCES \"Employee\" (\"EmployeeId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Customer table:\n",
      "CustomerId\tFirstName\tLastName\tCompany\tAddress\tCity\tState\tCountry\tPostalCode\tPhone\tFax\tEmail\tSupportRepId\n",
      "1\tLuís\tGonçalves\tEmbraer - Empresa Brasileira de Aeronáutica S.A.\tAv. Brigadeiro Faria Lima, 2170\tSão José dos Campos\tSP\tBrazil\t12227-000\t+55 (12) 3923-5555\t+55 (12) 3923-5566\tluisg@embraer.com.br\t3\n",
      "2\tLeonie\tKöhler\tNone\tTheodor-Heuss-Straße 34\tStuttgart\tNone\tGermany\t70174\t+49 0711 2842222\tNone\tleonekohler@surfeu.de\t5\n",
      "3\tFrançois\tTremblay\tNone\t1498 rue Bélanger\tMontréal\tQC\tCanada\tH2G 1A7\t+1 (514) 721-4711\tNone\tftremblay@gmail.com\t3\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE \"Invoice\" (\n",
      "\t\"InvoiceId\" INTEGER NOT NULL, \n",
      "\t\"CustomerId\" INTEGER NOT NULL, \n",
      "\t\"InvoiceDate\" DATETIME NOT NULL, \n",
      "\t\"BillingAddress\" NVARCHAR(70), \n",
      "\t\"BillingCity\" NVARCHAR(40), \n",
      "\t\"BillingState\" NVARCHAR(40), \n",
      "\t\"BillingCountry\" NVARCHAR(40), \n",
      "\t\"BillingPostalCode\" NVARCHAR(10), \n",
      "\t\"Total\" NUMERIC(10, 2) NOT NULL, \n",
      "\tPRIMARY KEY (\"InvoiceId\"), \n",
      "\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Invoice table:\n",
      "InvoiceId\tCustomerId\tInvoiceDate\tBillingAddress\tBillingCity\tBillingState\tBillingCountry\tBillingPostalCode\tTotal\n",
      "1\t2\t2009-01-01 00:00:00\tTheodor-Heuss-Straße 34\tStuttgart\tNone\tGermany\t70174\t1.98\n",
      "2\t4\t2009-01-02 00:00:00\tUllevålsveien 14\tOslo\tNone\tNorway\t0171\t3.96\n",
      "3\t8\t2009-01-03 00:00:00\tGrétrystraat 63\tBrussels\tNone\tBelgium\t1000\t5.94\n",
      "*/\n",
      "==================================================\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_OTx2gKtu3nOkeG19NBJSsViu)\n",
      " Call ID: call_OTx2gKtu3nOkeG19NBJSsViu\n",
      "  Args:\n",
      "    state: {'messages': [{'content': \"SELECT BillingCountry, SUM(Total) as TotalSpent FROM Invoice WHERE strftime('%Y', InvoiceDate) = '2009' GROUP BY BillingCountry ORDER BY TotalSpent DESC LIMIT 1;\", 'type': 'ai'}]}\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mquery_gen\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_OTx2gKtu3nOkeG19NBJSsViu)\n",
      " Call ID: call_OTx2gKtu3nOkeG19NBJSsViu\n",
      "  Args:\n",
      "    state: {'messages': [{'content': \"SELECT BillingCountry, SUM(Total) as TotalSpent FROM Invoice WHERE strftime('%Y', InvoiceDate) = '2009' GROUP BY BillingCountry ORDER BY TotalSpent DESC LIMIT 1;\", 'type': 'ai'}]}\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Error: The wrong tool was called: model_check_query. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\n",
      "==================================================\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "SELECT BillingCountry, SUM(Total) as TotalSpent FROM Invoice WHERE strftime('%Y', InvoiceDate) = '2009' GROUP BY BillingCountry ORDER BY TotalSpent DESC LIMIT 1;\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mquery_gen\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "SELECT BillingCountry, SUM(Total) as TotalSpent FROM Invoice WHERE strftime('%Y', InvoiceDate) = '2009' GROUP BY BillingCountry ORDER BY TotalSpent DESC LIMIT 1;\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mcorrect_query\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  db_query_tool (call_Rt5JisKxS1TC2pNZY3X103p7)\n",
      " Call ID: call_Rt5JisKxS1TC2pNZY3X103p7\n",
      "  Args:\n",
      "    query: SELECT BillingCountry, SUM(Total) as TotalSpent FROM Invoice WHERE strftime('%Y', InvoiceDate) = '2009' GROUP BY BillingCountry ORDER BY TotalSpent DESC LIMIT 1;\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mexecute_query\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: db_query_tool\n",
      "\n",
      "[('USA', 103.95)]\n",
      "==================================================\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Answer: 2009년도에 미국(USA) 고객이 가장 많이 지출했으며, 총 지출액은 103.95입니다.\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mquery_gen\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Answer: 2009년도에 미국(USA) 고객이 가장 많이 지출했으며, 총 지출액은 103.95입니다.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "output = run_graph(\n",
    "    \"2009년도에 어느 국가의 고객이 가장 많이 지출했을까요? 그리고 얼마를 지출했을까요? 한글로 답변하세요.\",\n",
    "    stream=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe744388",
   "metadata": {},
   "source": [
    "## LangSmith Evaluator 를 활용한 SQL Agent 평가\n",
    "\n",
    "이제 생성한 Agent 의 SQL 쿼리 응답을 평가합니다. 쿼리 응답을 평가하기 위한 평가용 데이터셋을 생성합니다.\n",
    "\n",
    "다음으로는 평가자를 정의하고 평가를 진행합니다.\n",
    "\n",
    "이때 활용하는 평가자는 LLM-as-judge 이며, 사용하는 프롬프트는 기본 hub 에서 제공하는 프롬프트를 활용합니다.\n",
    "\n",
    "다만, 보다 정확한 평가를 위해서 각자 프롬프트를 튜닝하여 사용하는 것을 권장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63565cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "# 클라이언트 초기화\n",
    "client = Client()\n",
    "\n",
    "# 데이터셋 생성 및 업로드\n",
    "examples = [\n",
    "    (\n",
    "        \"Which country's customers spent the most? And how much did they spend?\",\n",
    "        \"The country whose customers spent the most is the USA, with a total spending of 523.06.\",\n",
    "    ),\n",
    "    (\n",
    "        \"What was the most purchased track of 2013?\",\n",
    "        \"The most purchased track of 2013 was Hot Girl.\",\n",
    "    ),\n",
    "    (\n",
    "        \"How many albums does the artist Led Zeppelin have?\",\n",
    "        \"Led Zeppelin has 14 albums\",\n",
    "    ),\n",
    "    (\n",
    "        \"What is the total price for the album “Big Ones”?\",\n",
    "        \"The total price for the album 'Big Ones' is 14.85\",\n",
    "    ),\n",
    "    (\n",
    "        \"Which sales agent made the most in sales in 2009?\",\n",
    "        \"Steve Johnson made the most sales in 2009\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "dataset_name = \"SQL Agent Response\"\n",
    "\n",
    "if not client.has_dataset(dataset_name=dataset_name):\n",
    "    dataset = client.create_dataset(dataset_name=dataset_name)\n",
    "    inputs, outputs = zip(\n",
    "        *[({\"input\": text}, {\"output\": label}) for text, label in examples]\n",
    "    )\n",
    "    client.create_examples(inputs=inputs, outputs=outputs, dataset_id=dataset.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e01f99b",
   "metadata": {},
   "source": [
    "다음으로는 우리가 만든 에이전트의 SQL 쿼리 응답을 예측하기 위한 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a446fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에이전트의 SQL 쿼리 응답을 예측하기 위한 함수 정의\n",
    "def predict_sql_agent_answer(example: dict):\n",
    "    \"\"\"Use this for answer evaluation\"\"\"\n",
    "    config = RunnableConfig(configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "    inputs = {\n",
    "        \"messages\": [HumanMessage(content=example[\"input\"])],\n",
    "    }\n",
    "    # 그래프를 실행하여 메시지 결과 조회\n",
    "    messages = app.invoke(inputs, config)\n",
    "    answer = messages[\"messages\"][-1].content\n",
    "    # 결과 반환\n",
    "    return {\"response\": answer}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfecdfb1",
   "metadata": {},
   "source": [
    "SQL 쿼리 응답을 평가하기 위한 프롬프트와 평가자(LLM-as-judge) 를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f444566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Grade prompt\n",
    "grade_prompt_answer_accuracy = hub.pull(\"langchain-ai/rag-answer-vs-reference\")\n",
    "\n",
    "\n",
    "# 답변 평가자 LLM-as-judge 정의\n",
    "def answer_evaluator(run, example) -> dict:\n",
    "    # input: 질문\n",
    "    input_question = example.inputs[\"input\"]\n",
    "    # output: 참조 답변\n",
    "    reference = example.outputs[\"output\"]\n",
    "    # 예측 답변\n",
    "    prediction = run.outputs[\"response\"]\n",
    "\n",
    "    # LLM 평가자 초기화\n",
    "    llm = ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "    answer_grader = grade_prompt_answer_accuracy | llm\n",
    "\n",
    "    # 평가자 실행\n",
    "    score = answer_grader.invoke(\n",
    "        {\n",
    "            \"question\": input_question,\n",
    "            \"correct_answer\": reference,\n",
    "            \"student_answer\": prediction,\n",
    "        }\n",
    "    )\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    # 점수 반환\n",
    "    return {\"key\": \"answer_v_reference_score\", \"score\": score}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72159566",
   "metadata": {},
   "source": [
    "이제, 평가를 수행하고 결과를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "005efae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'sql-agent-eval-1d9b11a1' at:\n",
      "https://smith.langchain.com/o/a6a6ca30-b021-4af3-b5d0-a92f32e27c69/datasets/337f15e9-262c-4415-a4cd-e73d65737c62/compare?selectedSessions=680614c1-93f2-4fa9-b8a8-099596fd0364\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37dc76065638454cb106362886a23ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_SqsOIj5g4TiFeKmc3YX0w3MO)\n",
      " Call ID: call_SqsOIj5g4TiFeKmc3YX0w3MO\n",
      "  Args:\n",
      "    state: {'messages': [{'content': 'How many albums does the artist Led Zeppelin have?', 'type': 'human'}, {'content': 'Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track', 'type': 'function', 'name': 'sql_db_list_tables'}, {'content': 'CREATE TABLE \"Album\" (\\n\\t\"AlbumId\" INTEGER NOT NULL, \\n\\t\"Title\" NVARCHAR(160) NOT NULL, \\n\\t\"ArtistId\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"AlbumId\"), \\n\\tFOREIGN KEY(\"ArtistId\") REFERENCES \"Artist\" (\"ArtistId\")\\n)\\n\\n/*\\n3 rows from Album table:\\nAlbumId\\tTitle\\tArtistId\\n1\\tFor Those About To Rock We Salute You\\t1\\n2\\tBalls to the Wall\\t2\\n3\\tRestless and Wild\\t2\\n*/\\n\\n\\nCREATE TABLE \"Artist\" (\\n\\t\"ArtistId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(120), \\n\\tPRIMARY KEY (\"ArtistId\")\\n)\\n\\n/*\\n3 rows from Artist table:\\nArtistId\\tName\\n1\\tAC/DC\\n2\\tAccept\\n3\\tAerosmith\\n*/', 'type': 'function', 'name': 'sql_db_schema'}]}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```sql\n",
      "SELECT COUNT(*) \n",
      "FROM Album \n",
      "JOIN Artist ON Album.ArtistId = Artist.ArtistId \n",
      "WHERE Artist.Name = 'Led Zeppelin';\n",
      "```\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Answer: Led Zeppelin has 14 albums.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_K9W6mQAf1vLyeeswxdONvpx0)\n",
      " Call ID: call_K9W6mQAf1vLyeeswxdONvpx0\n",
      "  Args:\n",
      "    state: {'messages': [{'content': \"SELECT SUM(Invoice.Total) AS TotalPrice FROM Invoice \\nJOIN InvoiceLine ON Invoice.InvoiceId = InvoiceLine.InvoiceId \\nJOIN Track ON InvoiceLine.TrackId = Track.TrackId \\nJOIN Album ON Track.AlbumId = Album.AlbumId \\nWHERE Album.Title = 'Big Ones';\", 'type': 'ai'}]}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "SELECT SUM(Invoice.Total) AS TotalPrice FROM Invoice \n",
      "JOIN InvoiceLine ON Invoice.InvoiceId = InvoiceLine.InvoiceId \n",
      "JOIN Track ON InvoiceLine.TrackId = Track.TrackId \n",
      "JOIN Album ON Track.AlbumId = Album.AlbumId \n",
      "WHERE Album.Title = 'Big Ones';\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Answer: The total price for the album “Big Ones” is 82.17.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_8H4SZA1ssRNTwxm5PDguneMZ)\n",
      " Call ID: call_8H4SZA1ssRNTwxm5PDguneMZ\n",
      "  Args:\n",
      "    state: {'messages': [{'content': 'Which sales agent made the most in sales in 2009?', 'type': 'human'}, {'content': 'Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track', 'type': 'function', 'name': 'sql_db_list_tables'}, {'content': '{\"table_names\":\"Employee, Invoice, InvoiceLine\"}', 'type': 'function', 'name': 'sql_db_schema'}, {'content': '\\\\nCREATE TABLE \"Employee\" (\\\\n\\\\t\"EmployeeId\" INTEGER NOT NULL, \\\\n\\\\t\"LastName\" NVARCHAR(20) NOT NULL, \\\\n\\\\t\"FirstName\" NVARCHAR(20) NOT NULL, \\\\n\\\\t\"Title\" NVARCHAR(30), \\\\n\\\\t\"ReportsTo\" INTEGER, \\\\n\\\\t\"BirthDate\" DATETIME, \\\\n\\\\t\"HireDate\" DATETIME, \\\\n\\\\t\"Address\" NVARCHAR(70), \\\\n\\\\t\"City\" NVARCHAR(40), \\\\n\\\\t\"State\" NVARCHAR(40), \\\\n\\\\t\"Country\" NVARCHAR(40), \\\\n\\\\t\"PostalCode\" NVARCHAR(10), \\\\n\\\\t\"Phone\" NVARCHAR(24), \\\\n\\\\t\"Fax\" NVARCHAR(24), \\\\n\\\\t\"Email\" NVARCHAR(60), \\\\n\\\\tPRIMARY KEY (\"EmployeeId\"), \\\\n\\\\tFOREIGN KEY(\"ReportsTo\") REFERENCES \"Employee\" (\"EmployeeId\")\\\\n)\\\\n\\\\n/*\\\\n3 rows from Employee table:\\\\nEmployeeId\\\\tLastName\\\\tFirstName\\\\tTitle\\\\tReportsTo\\\\tBirthDate\\\\tHireDate\\\\tAddress\\\\tCity\\\\tState\\\\tCountry\\\\tPostalCode\\\\tPhone\\\\tFax\\\\tEmail\\\\n1\\\\tAdams\\\\tAndrew\\\\tGeneral Manager\\\\tNone\\\\t1962-02-18 00:00:00\\\\t2002-08-14 00:00:00\\\\t11120 Jasper Ave NW\\\\tEdmonton\\\\tAB\\\\tCanada\\\\tT5K 2N1\\\\t+1 (780) 428-9482\\\\t+1 (780) 428-3457\\\\tandrew@chinookcorp.com\\\\n2\\\\tEdwards\\\\tNancy\\\\tSales Manager\\\\t1\\\\t1958-12-08 00:00:00\\\\t2002-05-01 00:00:00\\\\t825 8 Ave SW\\\\tCalgary\\\\tAB\\\\tCanada\\\\tT2P 2T3\\\\t+1 (403) 262-3443\\\\t+1 (403) 262-3322\\\\tnancy@chinookcorp.com\\\\n3\\\\tPeacock\\\\tJane\\\\tSales Support Agent\\\\t2\\\\t1973-08-29 00:00:00\\\\t2002-04-01 00:00:00\\\\t1111 6 Ave SW\\\\tCalgary\\\\tAB\\\\tCanada\\\\tT2P 5M5\\\\t+1 (403) 262-3443\\\\t+1 (403) 262-6712\\\\tjane@chinookcorp.com\\\\n*/\\\\n\\\\n\\\\nCREATE TABLE \"Invoice\" (\\\\n\\\\t\"InvoiceId\" INTEGER NOT NULL, \\\\n\\\\t\"CustomerId\" INTEGER NOT NULL, \\\\n\\\\t\"InvoiceDate\" DATETIME NOT NULL, \\\\n\\\\t\"BillingAddress\" NVARCHAR(70), \\\\n\\\\t\"BillingCity\" NVARCHAR(40), \\\\n\\\\t\"BillingState\" NVARCHAR(40), \\\\n\\\\t\"BillingCountry\" NVARCHAR(40), \\\\n\\\\t\"BillingPostalCode\" NVARCHAR(10), \\\\n\\\\t\"Total\" NUMERIC(10, 2) NOT NULL, \\\\n\\\\tPRIMARY KEY (\"InvoiceId\"), \\\\n\\\\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\\\\n)\\\\n\\\\n/*\\\\n3 rows from Invoice table:\\\\nInvoiceId\\\\tCustomerId\\\\tInvoiceDate\\\\tBillingAddress\\\\tBillingCity\\\\tBillingState\\\\tBillingCountry\\\\tBillingPostalCode\\\\tTotal\\\\n1\\\\t2\\\\t2009-01-01 00:00:00\\\\tTheodor-Heuss-Straße 34\\\\tStuttgart\\\\tNone\\\\tGermany\\\\t70174\\\\t1.98\\\\n2\\\\t4\\\\t2009-01-02 00:00:00\\\\tUllevålsveien 14\\\\tOslo\\\\tNone\\\\tNorway\\\\t0171\\\\t3.96\\\\n3\\\\t8\\\\t2009-01-03 00:00:00\\\\tGrétrystraat 63\\\\tBrussels\\\\tNone\\\\tBelgium\\\\t1000\\\\t5.94\\\\n*/\\\\n\\\\n\\\\nCREATE TABLE \"InvoiceLine\" (\\\\n\\\\t\"InvoiceLineId\" INTEGER NOT NULL, \\\\n\\\\t\"InvoiceId\" INTEGER NOT NULL, \\\\n\\\\t\"TrackId\" INTEGER NOT NULL, \\\\n\\\\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \\\\n\\\\t\"Quantity\" INTEGER NOT NULL, \\\\n\\\\tPRIMARY KEY (\"InvoiceLineId\"), \\\\n\\\\tFOREIGN KEY(\"TrackId\") REFERENCES \"Track\" (\"TrackId\"), \\\\n\\\\tFOREIGN KEY(\"InvoiceId\") REFERENCES \"Invoice\" (\"InvoiceId\")\\\\n)\\\\n\\\\n/*\\\\n3 rows from InvoiceLine table:\\\\nInvoiceLineId\\\\tInvoiceId\\\\tTrackId\\\\tUnitPrice\\\\tQuantity\\\\n1\\\\t1\\\\t2\\\\t0.99\\\\t1\\\\n2\\\\t1\\\\t4\\\\t0.99\\\\t1\\\\n3\\\\t2\\\\t6\\\\t0.99\\\\t1\\\\n*/', 'type': 'function', 'name': 'sql_db_schema'}]}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```sql\n",
      "SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\n",
      "FROM Employee e\n",
      "JOIN Customer c ON e.EmployeeId = c.SupportRepId\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "WHERE strftime('%Y', i.InvoiceDate) = '2009'\n",
      "GROUP BY e.EmployeeId\n",
      "ORDER BY TotalSales DESC\n",
      "LIMIT 1;\n",
      "```\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Answer: The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_3fcWvsKjmXzJrd4ANMxptYJM)\n",
      " Call ID: call_3fcWvsKjmXzJrd4ANMxptYJM\n",
      "  Args:\n",
      "    state: {'messages': [{'content': 'What was the most purchased track of 2013?', 'type': 'human'}, {'content': 'InvoiceLine, Track', 'type': 'function', 'name': 'sql_db_list_tables'}, {'content': 'CREATE TABLE \"InvoiceLine\" (\\n\\t\"InvoiceLineId\" INTEGER NOT NULL, \\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \\n\\t\"Quantity\" INTEGER NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceLineId\"), \\n\\tFOREIGN KEY(\"TrackId\") REFERENCES \"Track\" (\"TrackId\"), \\n\\tFOREIGN KEY(\"InvoiceId\") REFERENCES \"Invoice\" (\"InvoiceId\")\\n)\\n\\n/*\\n3 rows from InvoiceLine table:\\nInvoiceLineId\\tInvoiceId\\tTrackId\\tUnitPrice\\tQuantity\\n1\\t1\\t2\\t0.99\\t1\\n2\\t1\\t4\\t0.99\\t1\\n3\\t2\\t6\\t0.99\\t1\\n*/\\n\\n\\nCREATE TABLE \"Track\" (\\n\\t\"TrackId\" INTEGER NOT NULL, \\n\\t\"Name\" NVARCHAR(200) NOT NULL, \\n\\t\"AlbumId\" INTEGER, \\n\\t\"MediaTypeId\" INTEGER NOT NULL, \\n\\t\"GenreId\" INTEGER, \\n\\t\"Composer\" NVARCHAR(220), \\n\\t\"Milliseconds\" INTEGER NOT NULL, \\n\\t\"Bytes\" INTEGER, \\n\\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"TrackId\"), \\n\\tFOREIGN KEY(\"MediaTypeId\") REFERENCES \"MediaType\" (\"MediaTypeId\"), \\n\\tFOREIGN KEY(\"GenreId\") REFERENCES \"Genre\" (\"GenreId\"), \\n\\tFOREIGN KEY(\"AlbumId\") REFERENCES \"Album\" (\"AlbumId\")\\n)\\n\\n/*\\n3 rows from Track table:\\nTrackId\\tName\\tAlbumId\\tMediaTypeId\\tGenreId\\tComposer\\tMilliseconds\\tBytes\\tUnitPrice\\n1\\tFor Those About To Rock (We Salute You)\\t1\\t1\\t1\\tAngus Young, Malcolm Young, Brian Johnson\\t343719\\t11170334\\t0.99\\n2\\tBalls to the Wall\\t2\\t2\\t1\\tNone\\t342562\\t5510424\\t0.99\\n3\\tFast As a Shark\\t3\\t2\\t1\\tF. Baltes, S. Kaufman, U. Dirkscneider & W. Hoffman\\t230619\\t3990994\\t0.99\\n*/', 'type': 'function', 'name': 'sql_db_schema'}]}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "SELECT Track.Name, SUM(InvoiceLine.Quantity) AS TotalQuantity\n",
      "FROM InvoiceLine\n",
      "JOIN Track ON InvoiceLine.TrackId = Track.TrackId\n",
      "JOIN Invoice ON InvoiceLine.InvoiceId = Invoice.InvoiceId\n",
      "WHERE strftime('%Y', Invoice.InvoiceDate) = '2013'\n",
      "GROUP BY Track.Name\n",
      "ORDER BY TotalQuantity DESC\n",
      "LIMIT 1;\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Answer: The most purchased track of 2013 was \"Where Eagles Dare\" with 2 purchases.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_1W6m0zIKKtD63yMdasK3AYSP)\n",
      " Call ID: call_1W6m0zIKKtD63yMdasK3AYSP\n",
      "  Args:\n",
      "    state: {'messages': [{'content': 'SELECT c.Country, SUM(i.Total) as TotalSpent FROM Customer c JOIN Invoice i ON c.CustomerId = i.CustomerId GROUP BY c.Country ORDER BY TotalSpent DESC LIMIT 1;', 'type': 'ai'}]}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "SELECT c.Country, SUM(i.Total) as TotalSpent FROM Customer c JOIN Invoice i ON c.CustomerId = i.CustomerId GROUP BY c.Country ORDER BY TotalSpent DESC LIMIT 1;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnxBnTOv8Sqd9rjhncsaDlRz on tokens per min (TPM): Limit 30000, Used 30000, Requested 201. Please try again in 402ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\1850029511.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2669, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2323, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\runner.py\", line 146, in tick\n",
      "    run_with_retry(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 600, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 365, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\2097126464.py\", line 46, in model_check_query\n",
      "    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3025, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5358, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 925, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnxBnTOv8Sqd9rjhncsaDlRz on tokens per min (TPM): Limit 30000, Used 30000, Requested 201. Please try again in 402ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'correct_query' and id 'c9f74d4d-2bbd-3c5c-3be5-2aa72a96b1ab'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run ac1e6e15-9dec-42ea-a4b7-b51909b32cc3: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\3301269268.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnxBnTOv8Sqd9rjhncsaDlRz on tokens per min (TPM): Limit 30000, Used 30000, Requested 43. Please try again in 86ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\1850029511.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2669, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2323, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\runner.py\", line 146, in tick\n",
      "    run_with_retry(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 600, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 365, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\2097126464.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5358, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 925, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnxBnTOv8Sqd9rjhncsaDlRz on tokens per min (TPM): Limit 30000, Used 30000, Requested 43. Please try again in 86ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id '1d786efd-3fac-5826-e6d4-10c5ff9132f6'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run e25d29aa-f3f7-42fb-9260-a489c0215a1b: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\3301269268.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnxBnTOv8Sqd9rjhncsaDlRz on tokens per min (TPM): Limit 30000, Used 30000, Requested 44. Please try again in 88ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\1850029511.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2669, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2323, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\runner.py\", line 146, in tick\n",
      "    run_with_retry(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 600, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 365, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\2097126464.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5358, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 925, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnxBnTOv8Sqd9rjhncsaDlRz on tokens per min (TPM): Limit 30000, Used 30000, Requested 44. Please try again in 88ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id '596f5e9c-44e2-bbdf-bf34-8307e73d4514'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 9ee6f53a-3b06-4005-8c35-b5177b435cf0: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\3301269268.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnxBnTOv8Sqd9rjhncsaDlRz on tokens per min (TPM): Limit 30000, Used 30000, Requested 43. Please try again in 86ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\1850029511.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2669, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2323, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\runner.py\", line 146, in tick\n",
      "    run_with_retry(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 600, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 365, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\2097126464.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5358, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 925, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnxBnTOv8Sqd9rjhncsaDlRz on tokens per min (TPM): Limit 30000, Used 30000, Requested 43. Please try again in 86ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id '90745235-8de5-0135-7c62-b7854f6e14cb'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 31076f5d-d80a-4dcb-be49-87a9099fe4fc: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\3301269268.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnxBnTOv8Sqd9rjhncsaDlRz on tokens per min (TPM): Limit 30000, Used 30000, Requested 41. Please try again in 82ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\1850029511.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2669, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2323, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\runner.py\", line 146, in tick\n",
      "    run_with_retry(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 600, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 365, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\2097126464.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5358, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 925, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnxBnTOv8Sqd9rjhncsaDlRz on tokens per min (TPM): Limit 30000, Used 30000, Requested 41. Please try again in 82ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id 'c214f9fd-2afa-847d-c394-fc72c49bc940'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 27e60ee0-d9ec-452f-85b4-838e96979e14: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\3301269268.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnxBnTOv8Sqd9rjhncsaDlRz on tokens per min (TPM): Limit 30000, Used 30000, Requested 48. Please try again in 96ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\1850029511.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2669, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2323, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\runner.py\", line 146, in tick\n",
      "    run_with_retry(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 600, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 365, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\2097126464.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5358, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 925, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnxBnTOv8Sqd9rjhncsaDlRz on tokens per min (TPM): Limit 30000, Used 30000, Requested 48. Please try again in 96ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id '8743f522-3200-f1da-10ec-6c1473a06f26'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 0b7be1c0-928c-449b-b0bc-31b74adc89a9: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\3301269268.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnxBnTOv8Sqd9rjhncsaDlRz on tokens per min (TPM): Limit 30000, Used 30000, Requested 43. Please try again in 86ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\1850029511.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2669, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2323, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\runner.py\", line 146, in tick\n",
      "    run_with_retry(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 600, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 365, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\2097126464.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5358, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 925, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnxBnTOv8Sqd9rjhncsaDlRz on tokens per min (TPM): Limit 30000, Used 30000, Requested 43. Please try again in 86ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id 'd1dcc44f-ff44-e9a4-77d5-bd48df29a8f6'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 04d5d200-74c7-48cb-89d7-c7a20f92beb4: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\3301269268.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnxBnTOv8Sqd9rjhncsaDlRz on tokens per min (TPM): Limit 30000, Used 29957, Requested 44. Please try again in 2ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\1850029511.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2669, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2323, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\runner.py\", line 146, in tick\n",
      "    run_with_retry(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 600, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 365, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\2097126464.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5358, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 925, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnxBnTOv8Sqd9rjhncsaDlRz on tokens per min (TPM): Limit 30000, Used 29957, Requested 44. Please try again in 2ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id 'b6774d4f-54ca-4ee2-d21d-1106e4dbee2d'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 61c4432e-1dc9-4bbe-a961-d19d16cc029b: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\3301269268.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_obCr80xxkmfEXUjSuLHtJ80V)\n",
      " Call ID: call_obCr80xxkmfEXUjSuLHtJ80V\n",
      "  Args:\n",
      "    state: {'messages': [{'content': 'Which sales agent made the most in sales in 2009?', 'type': 'human'}, {'content': 'Invoice, Employee', 'type': 'function', 'name': 'sql_db_list_tables'}, {'content': 'CREATE TABLE \"Employee\" (\\n\\t\"EmployeeId\" INTEGER NOT NULL, \\n\\t\"LastName\" NVARCHAR(20) NOT NULL, \\n\\t\"FirstName\" NVARCHAR(20) NOT NULL, \\n\\t\"Title\" NVARCHAR(30), \\n\\t\"ReportsTo\" INTEGER, \\n\\t\"BirthDate\" DATETIME, \\n\\t\"HireDate\" DATETIME, \\n\\t\"Address\" NVARCHAR(70), \\n\\t\"City\" NVARCHAR(40), \\n\\t\"State\" NVARCHAR(40), \\n\\t\"Country\" NVARCHAR(40), \\n\\t\"PostalCode\" NVARCHAR(10), \\n\\t\"Phone\" NVARCHAR(24), \\n\\t\"Fax\" NVARCHAR(24), \\n\\t\"Email\" NVARCHAR(60), \\n\\tPRIMARY KEY (\"EmployeeId\"), \\n\\tFOREIGN KEY(\"ReportsTo\") REFERENCES \"Employee\" (\"EmployeeId\")\\n)\\n\\n/*\\n3 rows from Employee table:\\nEmployeeId\\tLastName\\tFirstName\\tTitle\\tReportsTo\\tBirthDate\\tHireDate\\tAddress\\tCity\\tState\\tCountry\\tPostalCode\\tPhone\\tFax\\tEmail\\n1\\tAdams\\tAndrew\\tGeneral Manager\\tNone\\t1962-02-18 00:00:00\\t2002-08-14 00:00:00\\t11120 Jasper Ave NW\\tEdmonton\\tAB\\tCanada\\tT5K 2N1\\t+1 (780) 428-9482\\t+1 (780) 428-3457\\tandrew@chinookcorp.com\\n2\\tEdwards\\tNancy\\tSales Manager\\t1\\t1958-12-08 00:00:00\\t2002-05-01 00:00:00\\t825 8 Ave SW\\tCalgary\\tAB\\tCanada\\tT2P 2T3\\t+1 (403) 262-3443\\t+1 (403) 262-3322\\tnancy@chinookcorp.com\\n3\\tPeacock\\tJane\\tSales Support Agent\\t2\\t1973-08-29 00:00:00\\t2002-04-01 00:00:00\\t1111 6 Ave SW\\tCalgary\\tAB\\tCanada\\tT2P 5M5\\t+1 (403) 262-3443\\t+1 (403) 262-6712\\tjane@chinookcorp.com\\n*/\\n\\n\\nCREATE TABLE \"Invoice\" (\\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"InvoiceDate\" DATETIME NOT NULL, \\n\\t\"BillingAddress\" NVARCHAR(70), \\n\\t\"BillingCity\" NVARCHAR(40), \\n\\t\"BillingState\" NVARCHAR(40), \\n\\t\"BillingCountry\" NVARCHAR(40), \\n\\t\"BillingPostalCode\" NVARCHAR(10), \\n\\t\"Total\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceId\"), \\n\\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\\n)\\n\\n/*\\n3 rows from Invoice table:\\nInvoiceId\\tCustomerId\\tInvoiceDate\\tBillingAddress\\tBillingCity\\tBillingState\\tBillingCountry\\tBillingPostalCode\\tTotal\\n1\\t2\\t2009-01-01 00:00:00\\tTheodor-Heuss-Straße 34\\tStuttgart\\tNone\\tGermany\\t70174\\t1.98\\n2\\t4\\t2009-01-02 00:00:00\\tUllevålsveien 14\\tOslo\\tNone\\tNorway\\t0171\\t3.96\\n3\\t8\\t2009-01-03 00:00:00\\tGrétrystraat 63\\tBrussels\\tNone\\tBelgium\\t1000\\t5.94\\n*/', 'type': 'function', 'name': 'sql_db_schema'}]}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```sql\n",
      "SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\n",
      "FROM Employee e\n",
      "JOIN Customer c ON e.EmployeeId = c.SupportRepId\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "WHERE strftime('%Y', i.InvoiceDate) = '2009'\n",
      "GROUP BY e.EmployeeId\n",
      "ORDER BY TotalSales DESC\n",
      "LIMIT 1;\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnxBnTOv8Sqd9rjhncsaDlRz on tokens per min (TPM): Limit 30000, Used 30000, Requested 927. Please try again in 1.854s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\1850029511.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2669, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2323, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\runner.py\", line 146, in tick\n",
      "    run_with_retry(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 600, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 365, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\2097126464.py\", line 116, in query_gen_node\n",
      "    message = query_gen.invoke(state)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3025, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5358, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 925, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnxBnTOv8Sqd9rjhncsaDlRz on tokens per min (TPM): Limit 30000, Used 30000, Requested 927. Please try again in 1.854s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'query_gen' and id 'bffff237-5dea-c3d7-85dc-1d80e5423a10'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 40181104-8ec7-49ac-8483-2f86a2c4c70e: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\3301269268.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnxBnTOv8Sqd9rjhncsaDlRz on tokens per min (TPM): Limit 30000, Used 30000, Requested 41. Please try again in 82ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\1850029511.py\", line 10, in predict_sql_agent_answer\n",
      "    messages = app.invoke(inputs, config)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2669, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 2323, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\runner.py\", line 146, in tick\n",
      "    run_with_retry(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 600, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langgraph\\utils\\runnable.py\", line 365, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\2097126464.py\", line 65, in <lambda>\n",
      "    \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5358, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 925, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 914, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1242, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 919, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1008, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1057, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\openai\\_base_client.py\", line 1023, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnxBnTOv8Sqd9rjhncsaDlRz on tokens per min (TPM): Limit 30000, Used 30000, Requested 41. Please try again in 82ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "During task with name 'model_get_schema' and id '5d9c92b6-ad66-3469-2117-9139d2c6326b'\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run db47c7f1-d016-453c-a14f-bf99a9d5d39e: KeyError('response')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"c:\\Users\\susis\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-l86QH5WC-py3.11\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\susis\\AppData\\Local\\Temp\\ipykernel_8940\\3301269268.py\", line 15, in answer_evaluator\n",
      "    prediction = run.outputs[\"response\"]\n",
      "                 ~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'response'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  model_check_query (call_cGoDFk8iWrThwaHIdc3f0dvT)\n",
      " Call ID: call_cGoDFk8iWrThwaHIdc3f0dvT\n",
      "  Args:\n",
      "    state: {'messages': [{'content': \"Which country's customers spent the most? And how much did they spend?\", 'type': 'human'}, {'content': 'Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track', 'type': 'function', 'name': 'sql_db_list_tables'}, {'content': 'Customer, Invoice', 'type': 'function', 'name': 'sql_db_schema'}, {'content': 'CREATE TABLE \"Customer\" (\\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"FirstName\" NVARCHAR(40) NOT NULL, \\n\\t\"LastName\" NVARCHAR(20) NOT NULL, \\n\\t\"Company\" NVARCHAR(80), \\n\\t\"Address\" NVARCHAR(70), \\n\\t\"City\" NVARCHAR(40), \\n\\t\"State\" NVARCHAR(40), \\n\\t\"Country\" NVARCHAR(40), \\n\\t\"PostalCode\" NVARCHAR(10), \\n\\t\"Phone\" NVARCHAR(24), \\n\\t\"Fax\" NVARCHAR(24), \\n\\t\"Email\" NVARCHAR(60) NOT NULL, \\n\\t\"SupportRepId\" INTEGER, \\n\\tPRIMARY KEY (\"CustomerId\"), \\n\\tFOREIGN KEY(\"SupportRepId\") REFERENCES \"Employee\" (\"EmployeeId\")\\n)\\n\\n/*\\n3 rows from Customer table:\\nCustomerId\\tFirstName\\tLastName\\tCompany\\tAddress\\tCity\\tState\\tCountry\\tPostalCode\\tPhone\\tFax\\tEmail\\tSupportRepId\\n1\\tLuís\\tGonçalves\\tEmbraer - Empresa Brasileira de Aeronáutica S.A.\\tAv. Brigadeiro Faria Lima, 2170\\tSão José dos Campos\\tSP\\tBrazil\\t12227-000\\t+55 (12) 3923-5555\\t+55 (12) 3923-5566\\tluisg@embraer.com.br\\t3\\n2\\tLeonie\\tKöhler\\tNone\\tTheodor-Heuss-Straße 34\\tStuttgart\\tNone\\tGermany\\t70174\\t+49 0711 2842222\\tNone\\tleonekohler@surfeu.de\\t5\\n3\\tFrançois\\tTremblay\\tNone\\t1498 rue Bélanger\\tMontréal\\tQC\\tCanada\\tH2G 1A7\\t+1 (514) 721-4711\\tNone\\tftremblay@gmail.com\\t3\\n*/\\n\\n\\nCREATE TABLE \"Invoice\" (\\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"InvoiceDate\" DATETIME NOT NULL, \\n\\t\"BillingAddress\" NVARCHAR(70), \\n\\t\"BillingCity\" NVARCHAR(40), \\n\\t\"BillingState\" NVARCHAR(40), \\n\\t\"BillingCountry\" NVARCHAR(40), \\n\\t\"BillingPostalCode\" NVARCHAR(10), \\n\\t\"Total\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceId\"), \\n\\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\\n)\\n\\n/*\\n3 rows from Invoice table:\\nInvoiceId\\tCustomerId\\tInvoiceDate\\tBillingAddress\\tBillingCity\\tBillingState\\tBillingCountry\\tBillingPostalCode\\tTotal\\n1\\t2\\t2009-01-01 00:00:00\\tTheodor-Heuss-Straße 34\\tStuttgart\\tNone\\tGermany\\t70174\\t1.98\\n2\\t4\\t2009-01-02 00:00:00\\tUllevålsveien 14\\tOslo\\tNone\\tNorway\\t0171\\t3.96\\n3\\t8\\t2009-01-03 00:00:00\\tGrétrystraat 63\\tBrussels\\tNone\\tBelgium\\t1000\\t5.94\\n*/', 'type': 'function', 'name': 'sql_db_schema'}]}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```sql\n",
      "SELECT c.Country, SUM(i.Total) AS TotalSpent\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY TotalSpent DESC\n",
      "LIMIT 1;\n",
      "```\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Answer: The country's customers who spent the most are from the USA, with a total spending of 523.06.\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# 평가용 데이터셋 이름\n",
    "dataset_name = \"SQL Agent Response\"\n",
    "\n",
    "try:\n",
    "    # 평가 진행\n",
    "    experiment_results = evaluate(\n",
    "        predict_sql_agent_answer,  # 평가시 활용할 예측 함수\n",
    "        data=dataset_name,  # 평가용 데이터셋 이름\n",
    "        evaluators=[answer_evaluator],  # 평가자 목록\n",
    "        num_repetitions=3,  # 실험 반복 횟수 설정\n",
    "        experiment_prefix=\"sql-agent-eval\",\n",
    "        metadata={\"version\": \"chinook db, sql-agent-eval: gpt-4o\"},  # 실험 메타데이터\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239741fd",
   "metadata": {},
   "source": [
    "평가 결과는 생성된 URL 에서 각자 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c9d2ff",
   "metadata": {},
   "source": [
    "![](./assets/langgraph-sql-agent-evaluation.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-l86QH5WC-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
